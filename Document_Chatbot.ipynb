{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f59562a-eb68-4017-8c72-760cd033c958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('E:/Manohar/Document_Chatbot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127037e3-627b-467e-9cfd-a8bdec7cb500",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install sentence-transformers faiss-cpu llama-cpp-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7c486aa8-54a4-48f6-81ea-3f3a11aa8375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from ollama import Client, Options   # <-- import Options\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c40f9767-16b5-418c-acbd-96722c44680b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 chunks from 'Contracts/' directory.\n"
     ]
    }
   ],
   "source": [
    "# Function to load & chunk only .txt files under Contracts/\n",
    "def load_and_chunk(root_dir, chunk_size=500, overlap=100):\n",
    "    texts, metas = [], []\n",
    "    for dirpath, _, files in os.walk(root_dir):\n",
    "        for fn in files:\n",
    "            if not fn.lower().endswith(\".txt\"):\n",
    "                continue\n",
    "            full_path = os.path.join(dirpath, fn)\n",
    "            with open(full_path, encoding=\"utf8\", errors=\"ignore\") as f:\n",
    "                txt = f.read()\n",
    "            toks = txt.split()\n",
    "            for i in range(0, len(toks), chunk_size - overlap):\n",
    "                chunk = \" \".join(toks[i : i + chunk_size])\n",
    "                texts.append(chunk)\n",
    "                metas.append({\"source\": full_path, \"pos\": i})\n",
    "    return texts, metas\n",
    "\n",
    "# Load & chunk\n",
    "chunks, metadata = load_and_chunk(\"Contracts\")\n",
    "print(f\"Loaded {len(chunks)} chunks from 'Contracts/' directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4d06752d-cfbb-442c-bdf8-abf0b4c50dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  7.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built FAISS index with 3 vectors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Embed chunks and build FAISS index\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embs = embedder.encode(chunks, show_progress_bar=True)\n",
    "\n",
    "# Normalize and index\n",
    "faiss.normalize_L2(embs)\n",
    "index = faiss.IndexFlatIP(embs.shape[1])\n",
    "index.add(embs)\n",
    "\n",
    "print(f\"Built FAISS index with {index.ntotal} vectors.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88c5b8b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "753114e3-9483-4ef5-b3fe-f43d64dab4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated LLM\n"
     ]
    }
   ],
   "source": [
    "# Initialize Ollama client (make sure `ollama serve` is running)\n",
    "client = Client()\n",
    "\n",
    "# Helper to generate via local Llama 3 using Options for token limit\n",
    "def llm_generate(prompt, max_tokens=256):\n",
    "    opts = Options(num_predict=max_tokens)   # <-- use keyword arg\n",
    "    resp = client.chat(\n",
    "        model=\"llama3\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        options=opts\n",
    "    )\n",
    "    return resp[\"message\"][\"content\"]\n",
    "\n",
    "# RAG answer function\n",
    "def answer(query, k=5):\n",
    "    # 1) Embed & retrieve top-k\n",
    "    q_emb = embedder.encode([query])\n",
    "    faiss.normalize_L2(q_emb)\n",
    "    _, I = index.search(q_emb, k)\n",
    "\n",
    "    # 2) Build context\n",
    "    context = \"\\n\\n\".join(chunks[i] for i in I[0])\n",
    "    prompt = (\n",
    "        \"You are an assistant. Use the following context to answer the question.\\n\\n\"\n",
    "        f\"Context:\\n{context}\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "    )\n",
    "\n",
    "    # 3) Generate answer\n",
    "    return llm_generate(prompt)\n",
    "\n",
    "\n",
    "print(\"Generated LLM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "53ef65ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This contract, titled \"Master Services and Licensing Agreement\", is an agreement between Microsoft Corporation and LlamaLLC (Llama). The agreement outlines the terms and conditions for a licensing arrangement where Microsoft provides professional services and deliverables to Llama. The contract covers aspects such as confidentiality, intellectual property rights, data protection, indemnification, warranties, term and termination, and miscellaneous provisions.\n"
     ]
    }
   ],
   "source": [
    "# Quick test\n",
    "print(answer(\"What is this contract about?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f1102165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the contract, the following individuals signed it:\n",
      "\n",
      "* Sai Manohar, Data Scientist at Microsoft Corporation (dated June 5, 2025)\n",
      "* Tejas Gaikwad, AI Engineer at LlamaLLC (dated August 5, 2025)\n"
     ]
    }
   ],
   "source": [
    "# Quick test\n",
    "print(answer(\"Who signed this contract?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f7c268bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the Master Services and Licensing Agreement, I've highlighted the key points and listed them in order of importance:\n",
      "\n",
      "**Highly Important (1-3)**\n",
      "\n",
      "1. **Termination**: Either Party may terminate this Agreement without cause upon thirty (30) days written notice to the other Party. (§10.2)\n",
      "2. **Ownership**: Microsoft retains ownership of Intellectual Property Rights developed in connection with the Services or Deliverables. (§6.1)\n",
      "3. **Confidentiality**: Each Party agrees to protect Confidential Information disclosed by the other Party with the same degree of care it uses to protect its own confidential information. (§5.1)\n",
      "\n",
      "**Important (4-6)**\n",
      "\n",
      "4. **License Grant**: Microsoft grants Llama a limited, non-exclusive, non-transferable, and revocable license to use the Software identified in Exhibit B solely for Llama's internal business purposes. (§3.1)\n",
      "5. **Fees and Payment Terms**: Llama agrees to pay Microsoft the fees outlined in Exhibit C, with interest accruing at a rate of 1.5% per month or the maximum rate allowed by law if payments are late. (§4.2 & §4.3)\n",
      "6. **Governing\n"
     ]
    }
   ],
   "source": [
    "print(answer(\"Highlight key points and list them in order of importance\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28697cf9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7d8f10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
